---
title: "FF_00"
author: "Adaeze Ajoku"
date: "5/9/2017"
output: html_document
---

## Loading in libraries
```{r}
library(readr)
library(randomForest)
library(mice)
library(dplyr)
```

## Loading in datasets
```{r}
background <- read_csv("~/Desktop/Fragile Families/background.csv")
train <- read_csv("~/Desktop/Fragile Families/train.csv")
```

## Handling missing data
Interpretation:
-9 *Not in wave* – Did not participate in survey/data collection component
-8 Out of range – Response not possible; rarely used
-7 Not applicable (also -10/-14) – Rarely used for survey questions
-6 *Valid skip* – Intentionally not asked question; question does not apply to respondent or response known based on prior information.
-5 Not asked “Invalid skip” – Respondent not asked question in the version of the survey they received.
-3 Missing – Data is missing due to some other reason; rarely used
-2 *Don’t know* – Respondent asked question; Responded “Don’t Know”.
-1 *Refuse* – Respondent asked question; Refused to answer question

### (1) Change all negative values to NA and do multiple imputation
```{r}
background2 <- background
background2[background2 == -14 | background2 == -10 | background2 == -9 | background2 == -8 | background2 == -7 | background2 == -6 | background2 == -5 | background2 == -3 | background2 == -2 | background2 == -1] <- NA

## Subsetting to only year 9 to reduce computation time for multiple imputation
which(colnames(background2) == 'm5a2')
colnames(background2)[7420:12943]
background2.5 <- cbind(challengeID=background$challengeID, background2[,7420:12943])
background3 <- mice(background2.5, method='norm')

## Subsetting to just Material Hardship variables to further reduce computation time for multiple imputation
mHvars <- background2.5[, c('challengeID', 'm5f23a',  'f5f23a', 'm5f23b', 'f5f23b', 'm5e2', 'f5e2', 'm5f23c', 'f5f23c', 'm5f23d', 'f5f23d', 'm5f23e', 'f5f23e', 'm5f23f', 'f5f23f', 'm5f23g', 'f5f23g', 'm5f23h', 'f5f23h', 'm5f23i', 'f5f23i', 'm5f23j', 'f5f23j', 'm5f23k', 'f5f23k')]

## Remove rows that are all NAs
train2 <- train[apply(train[,-1], 1, function(y) !all(is.na(y))),]
mHvars2 <- mHvars[apply(mHvars[,-1], 1, function(y) !all(is.na(y))),]

miss <- anti_join(data.frame(challengeID=mHvars$challengeID), data.frame(challengeID=mHvars2$challengeID))
miss <- cbind(miss, materialHardship=rep(NA, length(miss)))

## Combine by challengeID
final <- merge(mHvars2, train2, by = "challengeID")

## Multiple Imputation
mHvars3 <- mice(final[,1:25])
mHvars3a <- mice(mHvars2)
train3 <- mice(final[,26:31])
final2 <- cbind(mHvars3, train3)
```

### (2) For entries of -6, look at the survey questionnaire to determine the skip pattern. What did these respondents tell us in prior questions that caused the interviewer to skip this question? Decide the correct way to code these values given your modeling approach.

## Linear Regression Model
```{r}
set.seed(357)
test <- complete(final2)
m1 <- lm(materialHardship~m5f23a + f5f23a + m5f23b + f5f23b + m5e2 + f5e2 + m5f23c + f5f23c + m5f23d + f5f23d + m5f23e + f5f23e + m5f23f + f5f23f + m5f23g + f5f23g + m5f23h + f5f23h + m5f23i + f5f23i + m5f23j + f5f23j + m5f23k + f5f23k, data=test)

p1 <- predict(m1, complete(mHvars3a))

#options(max.print=1000)

val <- data.frame(challengeID=mHvars2$challengeID, materialHardship=p1)
submit1 <- rbind(val, miss)
submit1 <- submit1[order(submit1$challengeID),]

write.csv(submit1,file="/Users/adaezeajoku/Desktop/Fragile\ Families/Submission1_MH.csv")

```

``` {r later}
p1 <- predict(m1, test$materialHardship)
sum(m1$fitted.values - test$materialHardship)^2 / length(test$materialHardship)

m1 <- with(final2,lm(materialHardship~ m5f23a + f5f23a + m5f23b + f5f23b + m5e2 + f5e2 + m5f23c + f5f23c + m5f23d + f5f23d + m5f23e + f5f23e + m5f23f + f5f23f + m5f23g + f5f23g + m5f23h + f5f23h + m5f23i + f5f23i + m5f23j + f5f23j + m5f23k + f5f23k))

p1 <- predict(pool(m1), complete(train3)$materialHardship)
sum(m1$fitted.values - p1)^2 / length(p1)
summary(pool(m1))
```

## Random Forests

